# app/services/generation_service.py
from __future__ import annotations

import json
import logging
import re
import traceback
from collections.abc import Callable
from functools import lru_cache
from typing import Any

from fastapi import HTTPException
from jinja2 import Environment, FileSystemLoader, TemplateNotFound

from app.services.external_sources import aggregated_search
from app.services.feedback_service import get_feedback_summary
from app.services.gigachat_service import get_available_giga_models, get_gigachat_client
from app.services.hf_infer_service import get_available_hf_models, get_hf_client
from app.services.llm_types import LLMClient

# –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ –∏–∑ app/routes/generation.py

def course_kwargs(course, cs=None):
    data = {
        "course_name": course.name,
        "course_description": course.description,
        "course_level": course.level,
    }
    if cs:
        data.update({
            "module_count": cs.sections,
            "lessons_per_section": cs.lessons_per_section,
        })
    return data


def llm_json(template: str, *, engine: str, model: str | None, **kwargs) -> dict[str, Any]:
    """
    –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±—ë—Ä—Ç–∫–∞: –æ—Ç–¥–∞—ë—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç LLM —Å –ø–∞—Ä—Å–∏–Ω–≥–æ–º –∏ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫,
    –ø—Ä–æ–≤–æ–¥–∏—Ç –ª–æ–≥–∏ –ø–æ –æ—à–∏–±–∫–∞–º –∏ —Ö–µ–Ω–¥–ª–∏—Ç HTTP-exception.
    """
    try:
        return generate_from_prompt(
            template_name=template,
            engine=engine,
            model_name=model,
            expect_json=True,
            include_external_context=False,
            use_feedback=False,
            **kwargs,
        )
    except Exception as e:
        logger.error("LLM error in llm_json: %s\n%s", e, traceback.format_exc())
        raise HTTPException(500, f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ LLM: {e}")

# -------------------- Setup --------------------
env = Environment(loader=FileSystemLoader("app/prompts"))
logger = logging.getLogger(__name__)

# –§–∞–±—Ä–∏–∫–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤
SUPPORTED_ENGINES: dict[str, Callable[[str | None], tuple[LLMClient, str]]] = {
    "hf_api": get_hf_client,
    "gigachat": get_gigachat_client,
}

# –ê–ª–∏–∞—Å—ã –æ—Ç —Å—Ç–∞—Ä–æ–≥–æ –∫–æ–¥–∞/—Ñ—Ä–æ–Ω—Ç–∞
ENGINE_ALIASES: dict[str, str] = {
    "lc_giga": "gigachat",
    "lc_gc": "gigachat",
    "lc_hf": "hf_api",
}

DEFAULT_ENGINE = "gigachat"
DEFAULT_MAX_TOKENS = 1024
DEFAULT_MODEL: str | None = None

# -------------------- Utils --------------------
JSON_BLOCK_RE = re.compile(r"\{[\s\S]*\}", re.MULTILINE)


def _safe_json_loads(raw: str) -> dict[str, Any]:
    """
    –ü—ã—Ç–∞–µ–º—Å—è –≤—ã—Ç–∞—â–∏—Ç—å –≤–∞–ª–∏–¥–Ω—ã–π JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏.
    1) –£–±–∏—Ä–∞–µ–º –æ–±—ë—Ä—Ç–∫–∏ ```json ... ```
    2) –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞–ø—Ä—è–º—É—é
    3) –ò—â–µ–º —Å–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π {...} –±–ª–æ–∫
    4) –ú–∏–Ω–∏-—Ñ–∏–∫—Å—ã (–æ–¥–∏–Ω–æ—á–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ -> –¥–≤–æ–π–Ω—ã–µ)
    """
    cleaned = raw.strip()
    cleaned = cleaned.replace("```json", "").replace("```", "").strip()

    # –ü—Ä—è–º–∞—è –ø–æ–ø—ã—Ç–∫–∞
    try:
        return json.loads(cleaned)
    except Exception:
        pass

    # –ò—â–µ–º –±–ª–æ–∫–∏ {...}
    candidates = JSON_BLOCK_RE.findall(cleaned)
    candidates.sort(key=len, reverse=True)
    for c in candidates:
        try:
            return json.loads(c)
        except Exception:
            # –ü—Ä–æ—Å—Ç–µ–π—à–∏–π —Ñ–∏–∫—Å –∫–∞–≤—ã—á–µ–∫
            fixed = re.sub(r"(?<!\\)'", '"', c)
            try:
                return json.loads(fixed)
            except Exception:
                continue

    raise HTTPException(500, "–û—à–∏–±–∫–∞ —Ä–∞–∑–±–æ—Ä–∞ JSON –æ—Ç LLM")


@lru_cache(maxsize=128)
def get_cached_external_context(query: str, lang: str = "ru") -> str:
    try:
        results = aggregated_search(query=query, source="all", lang=lang)
        return "\n\n".join(results)
    except Exception as e:
        logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤–Ω–µ—à–Ω–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: %s", e)
        return ""


def render_prompt(template_name: str, **kwargs) -> str:
    try:
        template = env.get_template(template_name)
    except TemplateNotFound:
        raise HTTPException(400, f"–®–∞–±–ª–æ–Ω '{template_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
    return template.render(**kwargs)


# -------------------- Public API --------------------
def generate_from_prompt(
    template_name: str | None = None,
    *,
    prompt: str | None = None,
    engine: str = DEFAULT_ENGINE,
    model_name: str | None = None,
    include_external_context: bool = True,
    use_feedback: bool = True,
    lang: str = "ru",
    db: Any = None,
    expect_json: bool = True,
    max_tokens: int = DEFAULT_MAX_TOKENS,
    **kwargs: Any,
) -> dict[str, Any]:
    """
    –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–∑–æ–≤ LLM.

    - template_name: –∏–º—è jinja2-—à–∞–±–ª–æ–Ω–∞ (app/prompts)
    - prompt: –ø—Ä—è–º–æ–π —Ç–µ–∫—Å—Ç –ø—Ä–æ–º–ø—Ç–∞ (–µ—Å–ª–∏ template_name –Ω–µ —É–∫–∞–∑–∞–Ω)
    - engine/model_name: –≤—ã–±–æ—Ä –¥–≤–∏–∂–∫–∞/–º–æ–¥–µ–ª–∏
    - include_external_context: –≤—Å—Ç–∞–≤–ª—è—Ç—å aggregated_search
    - use_feedback: –¥–æ–±–∞–≤–ª—è—Ç—å summary –æ—Ç–∑—ã–≤–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å db –∏ lesson_id)
    - expect_json: –ø—ã—Ç–∞—Ç—å—Å—è –ø–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç –∫–∞–∫ JSON
    - max_tokens: –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–µ—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç)
    """

    # ---- –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–≤–∏–∂–æ–∫ ----
    engine = ENGINE_ALIASES.get(engine, engine)
    if engine not in SUPPORTED_ENGINES:
        raise HTTPException(400, f"‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –¥–≤–∏–∂–æ–∫: {engine}")

    # ---- —Ñ–æ—Ä–º–∏—Ä—É–µ–º prompt ----
    if template_name:
        if include_external_context:
            cq = kwargs.get("course_name") or kwargs.get("lesson_title")
            kwargs["external_context"] = get_cached_external_context(cq, lang) if cq else ""
        else:
            kwargs["external_context"] = ""

        if use_feedback and db is not None and "lesson_id" in kwargs:
            try:
                kwargs["feedback_context"] = get_feedback_summary(kwargs["lesson_id"], db)
            except Exception as e:
                logger.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ feedback_context: %s", e)
                kwargs["feedback_context"] = ""
        else:
            kwargs["feedback_context"] = ""

        final_prompt = render_prompt(template_name, **kwargs)
    else:
        final_prompt = prompt or kwargs.get("prompt")
        if not final_prompt:
            raise HTTPException(400, "–ù–µ –ø–µ—Ä–µ–¥–∞–Ω template_name –∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç prompt")

    logger.info("üì§ Prompt:\n%s", final_prompt)

    # ---- –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç–∞ ----
    try:
        ctor = SUPPORTED_ENGINES[engine]
        client, used_model = ctor(model_name)
    except HTTPException:
        raise
    except Exception as e:
        logger.error(
            "‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–≤–∏–∂–∫–∞ %s: %s\n%s",
            engine,
            e,
            traceback.format_exc(),
        )
        raise HTTPException(500, f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ LLM: {e}")

    # ---- –≤—ã–∑–æ–≤ –º–æ–¥–µ–ª–∏ ----
    try:
        try:
            raw = client.generate(final_prompt, max_tokens=max_tokens)
        except TypeError:
            # —Å–∏–≥–Ω–∞—Ç—É—Ä–∞ –±–µ–∑ max_tokens
            raw = client.generate(final_prompt)
    except Exception as e:
        logger.error("‚ùå –û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ LLM: %s\n%s", e, traceback.format_exc())
        raise HTTPException(500, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –º–æ–¥–µ–ª–∏: {e}")

    raw_clean = (raw or "").strip()
    logger.info("üì• Raw output (%s):\n%s", used_model, raw_clean)

    if not expect_json:
        return {"text": raw_clean, "model": used_model}

    try:
        res = _safe_json_loads(raw_clean)
        res["_model"] = used_model
        return res
    except HTTPException:
        raise
    except Exception:
        logger.error("‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON:\n%s", traceback.format_exc())
        raise HTTPException(500, "–û—à–∏–±–∫–∞ —Ä–∞–∑–±–æ—Ä–∞ JSON –æ—Ç LLM")


def list_available_models() -> list[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (HF + GigaChat)."""
    try:
        hf = get_available_hf_models()
    except Exception as e:
        logger.warning("HF list error: %s", e)
        hf = []
    try:
        gg = get_available_giga_models()
    except Exception as e:
        logger.warning("GigaChat list error: %s", e)
        gg = []
    return hf + gg
